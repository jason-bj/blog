<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon/favicon-16x16.png">
  <meta name="google-site-verification" content="xitt2fbphh1nTeWLiTWc0lCggHuxJ5heMcAzkHW2vno">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Microsoft+YaHei+UI:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"cyun.tech","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null,"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":10,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Performance knowledgeMemory Usage Metric123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354Show process memory usage by top  PID USER      PR  NI    VIR">
<meta property="og:type" content="article">
<meta property="og:title" content="performance tools">
<meta property="og:url" content="http://cyun.tech/2019/09/26/linux-performance-tools/index.html">
<meta property="og:site_name" content="CYun">
<meta property="og:description" content="Performance knowledgeMemory Usage Metric123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354Show process memory usage by top  PID USER      PR  NI    VIR">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-09-26T06:05:50.000Z">
<meta property="article:modified_time" content="2023-08-16T15:02:01.162Z">
<meta property="article:author" content="Jason">
<meta property="article:tag" content="performance">
<meta property="article:tag" content="perf">
<meta property="article:tag" content="gperftools">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://cyun.tech/2019/09/26/linux-performance-tools/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://cyun.tech/2019/09/26/linux-performance-tools/","path":"2019/09/26/linux-performance-tools/","title":"performance tools"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>performance tools | CYun</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-148730544-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-148730544-1","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?a510d1f580c8231f8f867d14f42bb8ea"></script>




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">CYun</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Performance-knowledge"><span class="nav-number">1.</span> <span class="nav-text">Performance knowledge</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Memory-Usage-Metric"><span class="nav-number">1.1.</span> <span class="nav-text">Memory Usage Metric</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#load-average"><span class="nav-number">1.2.</span> <span class="nav-text">load average</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#troubleshooting-high-load-average"><span class="nav-number">1.2.1.</span> <span class="nav-text">troubleshooting high load average</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CPU-usage"><span class="nav-number">1.3.</span> <span class="nav-text">CPU usage</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cpu-usage-vs-load-average"><span class="nav-number">1.4.</span> <span class="nav-text">cpu usage vs load average</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#useful-commands-and-performance-tools"><span class="nav-number">2.</span> <span class="nav-text">useful commands and performance tools</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#useful-commands"><span class="nav-number">2.1.</span> <span class="nav-text">useful commands</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#check-bottleneck-call-graph"><span class="nav-number">2.2.</span> <span class="nav-text">check bottleneck, call graph</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#gperftools-great-perf-tools-originally-from-google-performance-tool-is-package-name"><span class="nav-number">2.2.1.</span> <span class="nav-text">gperftools(great perf tools, originally from google performance tool, is package name)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Ref"><span class="nav-number">3.</span> <span class="nav-text">Ref</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jason"
      src="/uploads/avatar.gif">
  <p class="site-author-name" itemprop="name">Jason</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">149</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">141</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">149</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/jason-cyun" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;jason-cyun" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:jason_lkm@163.com" title="E-Mail → mailto:jason_lkm@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://cyun.tech/2019/09/26/linux-performance-tools/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.gif">
      <meta itemprop="name" content="Jason">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CYun">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="performance tools | CYun">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          performance tools
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2019-09-26 14:05:50" itemprop="dateCreated datePublished" datetime="2019-09-26T14:05:50+08:00">2019-09-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-08-16 23:02:01" itemprop="dateModified" datetime="2023-08-16T23:02:01+08:00">2023-08-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/performance/" itemprop="url" rel="index"><span itemprop="name">performance</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/performance/application/" itemprop="url" rel="index"><span itemprop="name">application</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="Performance-knowledge"><a href="#Performance-knowledge" class="headerlink" title="Performance knowledge"></a>Performance knowledge</h1><h2 id="Memory-Usage-Metric"><a href="#Memory-Usage-Metric" class="headerlink" title="Memory Usage Metric"></a>Memory Usage Metric</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">Show process memory usage by top</span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line"></span><br><span class="line">    1 root      20   0   38116   6136   3984 S   0.0  0.0   0:05.71 systemd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    VIRT(VSS): The total amount of virtual memory used by the task.</span><br><span class="line">               It includes all code, data and shared libraries plus pages that have been swapped out(it not real physical memory current used)</span><br><span class="line"></span><br><span class="line">    RES(RSS):  The non-swapped physical memory a task has used, CODE+DATA</span><br><span class="line"></span><br><span class="line">    SHR:       The amount of shared memory used by a task.</span><br><span class="line">               It simply reflects memory that could be potentially shared with other processes.</span><br><span class="line"></span><br><span class="line">    %MEM:      Memory usage (RES)</span><br><span class="line"></span><br><span class="line">Show process memory usage by smem (metric used by smem and ps)</span><br><span class="line"></span><br><span class="line">    Swap: Swap size used by each process</span><br><span class="line"></span><br><span class="line">    VSS(virtual set size)</span><br><span class="line">         VSS (reported as VSZ from ps)is the total accessible address space of a process</span><br><span class="line">         (all allocated virtual addresses like malloc, stack, map(shared library))</span><br><span class="line">         This size also includes memory that may not be resident in RAM like mallocs that have been allocated but not written to.</span><br><span class="line">         VSS is of very little use for determining real memory usage of a process.</span><br><span class="line"></span><br><span class="line">    RSS(resident set size)</span><br><span class="line">        RSS is the total memory actually held in RAM for a process. RSS can be misleading,</span><br><span class="line">        because it reports the total all of the shared libraries that the process uses,</span><br><span class="line">        even though a shared library is only loaded into memory once regardless of how many processes use it.</span><br><span class="line">        RSS is not an accurate representation of the memory usage for a single process.</span><br><span class="line"></span><br><span class="line">    PSS(Proportional set size)</span><br><span class="line">        PSS differs from RSS in that it reports the proportional size of its shared libraries,</span><br><span class="line">        i.e.if three processes all use a shared library that has 30 pages,</span><br><span class="line">        that library will only contribute 10 pages to the PSS that is reported for each of the three processes.</span><br><span class="line">        PSS is a very useful number because when the PSS for all processes in the system are summed together,</span><br><span class="line">        that is a good representation for the total memory usage in the system.</span><br><span class="line">        When a process is killed, the shared libraries that contributed to its PSS will be proportionally distributed to</span><br><span class="line">        the PSS totals for the remaining processes still using that library.</span><br><span class="line">        In this way PSS can be slightly misleading, because when a process is killed, PSS does not accurately represent the memory returned to the overall system.</span><br><span class="line"></span><br><span class="line">    USS(unique set size)</span><br><span class="line">        USS is the total private memory for a process, i.e. that memory that is completely unique to that process.</span><br><span class="line">        USS is an extremely useful number because it indicates the true incremental cost of running a particular process.</span><br><span class="line">        When a process is killed, the USS is the total memory that is actually returned to the system.</span><br><span class="line">        USS is the best number to watch when initially suspicious of memory leaks in a process.</span><br><span class="line"></span><br><span class="line">    For example, there are two processes share a library which takes 2M physical memory</span><br><span class="line"></span><br><span class="line">                VSS     RSS     PSS     USS</span><br><span class="line">    process A   20M     18M     17M     16M</span><br><span class="line">    process B   20M     19M     18M     17M</span><br><span class="line">    (RSS=USS+shared_library_memory, PSS=USS+shared_library_memory/shared_process_count)</span><br></pre></td></tr></table></figure>

<h2 id="load-average"><a href="#load-average" class="headerlink" title="load average"></a>load average</h2><p>The load average is the <code>average system load</code> on a Linux server <code>for a defined period of time</code>. In other words, it is the CPU demand of a server that includes sum of the running and the waiting threads. <strong>on linux, it not only tracks running tasks, but also tasks in uninterruptible sleep (usually waiting for IO)</strong></p>
<p>Measuring the load average is critical to understanding how your servers are performing; <code>if overloaded, you need to kill or optimize the processes consuming high amounts of resources, or provide more resources to balance the workload</code>.</p>
<p><code>For simple, let&#39;s assume a server with a single processor, if the load is less than 1, that means on average, every process that needed the CPU could use it immediately without being blocked. Conversely, if the load is greater than 1, that means on average, there were processes ready to run, but could not due to CPUs being unavailable.</code></p>
<p>For a single processor, ideal load average is 1.00, and anything above that is an action call to troubleshoot? Well, although it’s a safe bet, a more proactive approach is leaving some extra headroom to manage unexpected loads, many people <code>tend to aim for a load number of about 0.7 to cater for the spikes</code></p>
<p><strong>overloaded or not depends on how may cpus(not core) you have</strong></p>
<p>You probably have a system with multiple CPUs. The load average numbers work a bit differently on such a system. For example, <code>if you have a load average of 2 on a single-CPU system, this means your system was overloaded by 100 percent</code> — the entire period of time, one process was using the CPU while one other process was waiting. <code>On a system with two CPUs, this would be complete usage — two different processes were using two different CPUs the entire time</code>. On a system with four CPUs, this would be half usage — two processes were using two CPUs, while two CPUs were sitting idle.</p>
<span id="more"></span>

<p><strong>check load average</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(py3.9) [root@dev ~]<span class="comment"># uptime</span></span><br><span class="line"> 14:41:58 up 11 days, 23:10,  3 <span class="built_in">users</span>,  load average: 1.68, 0.55, 5.91</span><br><span class="line"> <span class="comment"># These numbers are the averages of the system load over a period of one, five, and 15 minutes</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>The first value is 1.68. This is the value of CPU load during the last minute. <code>this is a measure of how many programs(process in ready state) were using CPU time during the last minute</code>. So, during the last minute on this machine, <code>there were an average of 1.68 programs either using CPU processing time or waiting for CPU processing time</code>. If this is a single-threaded CPU, that means the computer is overloaded. Users are waiting for their programs to run on the CPU, and experiencing degraded performance. If, instead, this is a dual-core computer or a quad-core, users are able to get CPU time just as quickly as they needed it, during the last minute.</p>
</li>
<li><p>The second value is 0.55. This is the measurement over the last 5 minutes. As we previously discussed, a measurement below 1 means that the CPU spent some of the time in that window completely idle. In this case, the CPU was idle for almost half the time. If we’re optimizing our CPU to be constantly doing something, that’s not a good sign.</p>
</li>
<li><p>The final number, 5.91, is a measurement of the last 15 minutes. If you’re using an eight-core CPU, then this number isn’t particularly shocking. If you’re using a dual-core CPU, then a number like 5.91 means your CPU is very overloaded. Users are regularly waiting for CPU time, and are probably experiencing significantly degraded performance.</p>
</li>
</ul>
<h3 id="troubleshooting-high-load-average"><a href="#troubleshooting-high-load-average" class="headerlink" title="troubleshooting high load average"></a>troubleshooting high load average</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># show current load average</span></span><br><span class="line">$ <span class="built_in">uptime</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">########################################################## cpu usage per cpu====================================</span></span><br><span class="line"><span class="comment"># show per-cpu usage peridically</span></span><br><span class="line">$ mpstat -P ALL 1</span><br><span class="line"><span class="comment">########################################################## cpu usage per cpu====================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########################################################## cpu usage per process====================================</span></span><br><span class="line"><span class="comment"># show all active process cpu usage(like top)</span></span><br><span class="line"><span class="variable">$pidstat</span> 1</span><br><span class="line"><span class="comment"># show cpu usage of given process peridically(2 second)</span></span><br><span class="line"><span class="comment"># $pidstat -p 823471  2</span></span><br><span class="line"><span class="variable">$pidstat</span> -p 823471  1</span><br><span class="line">Linux 3.10.0-693.21.7.el7.x86_64 (A06-R08-I132-181-815KSRH.JCLOUD.COM)  07/20/2022      _x86_64_        (32 CPU)</span><br><span class="line">04:42:46 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">04:42:47 PM     0    823471   33.00    5.00    0.00   38.00    10  node_monitor</span><br><span class="line">04:42:48 PM     0    823471   54.00    7.00    0.00   61.00    10  node_monitor</span><br><span class="line">04:42:49 PM     0    823471   46.00    4.00    0.00   50.00    10  node_monitor</span><br><span class="line">04:42:50 PM     0    823471   31.00    7.00    0.00   38.00    10  node_monitor</span><br><span class="line"><span class="comment"># show cpu usage of given process(thread displayed)peridically</span></span><br><span class="line"><span class="variable">$pidstat</span> -p 823471 -t 1</span><br><span class="line"><span class="comment">########################################################## cpu usage per process====================================</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">########################################################## cpu schedule latency per process=========================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># CPU run queue latency, schedule latency for each process</span></span><br><span class="line"><span class="comment"># monitor 10 seconds</span></span><br><span class="line">$ perf <span class="built_in">sched</span> record -- <span class="built_in">sleep</span> 10</span><br><span class="line">$ perf <span class="built_in">sched</span> latency</span><br><span class="line"> -----------------------------------------------------------------------------------------------------------------</span><br><span class="line">  Task                  |   Runtime ms  | Switches | Average delay ms | Maximum delay ms | Maximum delay at       |</span><br><span class="line"> -----------------------------------------------------------------------------------------------------------------</span><br><span class="line">  :632308:632308        |      0.478 ms |        2 | avg:   47.545 ms | max:   95.088 ms | max at: 1397496.686810 s</span><br><span class="line">  :632316:632316        |     13.820 ms |        8 | avg:   23.729 ms | max:   94.070 ms | max at: 1397496.685531 s</span><br><span class="line">  ovs-vsctl:(3)         |    107.932 ms |       31 | avg:   14.581 ms | max:   95.035 ms | max at: 1397496.485498 s</span><br><span class="line">  sh:(2)                |      6.058 ms |       11 | avg:    8.146 ms | max:   87.049 ms | max at: 1397495.885529 s</span><br><span class="line">  <span class="built_in">sleep</span>:(26)            |     17.129 ms |       75 | avg:    6.211 ms | max:   94.541 ms | max at: 1397496.386032 s</span><br><span class="line">  :632320:632320        |      3.305 ms |       18 | avg:    5.288 ms | max:   94.205 ms | max at: 1397495.785685 s</span><br><span class="line">  node_monitor:(76)     |    342.577 ms |     2342 | avg:    4.063 ms | max:  192.182 ms | max at: 1397496.385540 s</span><br><span class="line">  perf:(183)            |    569.297 ms |     1597 | avg:    3.975 ms | max:  196.652 ms | max at: 1397496.386045 s</span><br><span class="line">  kworker/25:2:461486   |      0.009 ms |        1 | avg:    0.677 ms | max:    0.677 ms | max at: 1397496.187200 s</span><br><span class="line">  kworker/9:1:30855     |      0.012 ms |        1 | avg:    0.379 ms | max:    0.379 ms | max at: 1397496.186873 s</span><br><span class="line">  kworker/1:6:615135    |      0.022 ms |        2 | avg:    0.358 ms | max:    0.711 ms | max at: 1397496.189183 s</span><br><span class="line">  kworker/17:1:715010   |      0.009 ms |        1 | avg:    0.357 ms | max:    0.357 ms | max at: 1397496.186876 s</span><br><span class="line">  kworker/31:1:303204   |      0.011 ms |        1 | avg:    0.314 ms | max:    0.314 ms | max at: 1397496.186854 s</span><br><span class="line">  :632321:632321        |      3.882 ms |        7 | avg:    0.313 ms | max:    1.140 ms | max at: 1397495.887512 s</span><br><span class="line">  :632319:632319        |      0.815 ms |        6 | avg:    0.258 ms | max:    1.277 ms | max at: 1397495.792539 s</span><br><span class="line">  kworker/3:1:86183     |      0.010 ms |        1 | avg:    0.226 ms | max:    0.226 ms | max at: 1397496.186715 s</span><br><span class="line">  :632317:632317        |      0.866 ms |        7 | avg:    0.216 ms | max:    1.099 ms | max at: 1397495.794319 s</span><br><span class="line">  kworker/14:1:197420   |      0.010 ms |        1 | avg:    0.215 ms | max:    0.215 ms | max at: 1397496.186723 s</span><br><span class="line">  :632307:632307        |      0.872 ms |        8 | avg:    0.205 ms | max:    1.420 ms | max at: 1397496.188524 s</span><br><span class="line">  kworker/26:0:308384   |      0.011 ms |        1 | avg:    0.193 ms | max:    0.193 ms | max at: 1397496.186720 s</span><br><span class="line">  :632301:632301        |      0.275 ms |        4 | avg:    0.165 ms | max:    0.658 ms | max at: 1397496.591534 s</span><br><span class="line"></span><br><span class="line"><span class="comment">########################################################## cpu schedule latency per process=========================</span></span><br></pre></td></tr></table></figure>

<h2 id="CPU-usage"><a href="#CPU-usage" class="headerlink" title="CPU usage"></a>CPU usage</h2><p>CPU usage is a measurement, in a percentage, of how much time the CPU spends actively computing something. For instance, if you had a program that required uninterrupted processing power for 54 out of the last 60 seconds, your CPU usage on one core would be 90%. Instead, if the program only required six seconds processing time on one core, the usage would be 10%.</p>
<p><code>Most companies seek to keep the CPU usage of their servers as close to 100% as possible</code>. Most servers are sold by overall computing power, and if your server is only sitting at 30% CPU usage, you’re paying for too much processor power. You could downgrade your processor to a lower tier, save money, and see no reduction in the quality of your server’s performance.</p>
<h2 id="cpu-usage-vs-load-average"><a href="#cpu-usage-vs-load-average" class="headerlink" title="cpu usage vs load average"></a>cpu usage vs load average</h2><p>CPU usage: There ratio (usually expressed as a percentage)of time that the CPU is busy doing stuff. This measure only makes sense if you know over which period the percentage is being calculated.</p>
<p>Load: <code>Average queue length for the CPU - including the process currently executing</code>. For this to make sense, you need to know the period over which this is being measured.</p>
<p><strong>They are related, but one does not necessarily correlate to the other.</strong></p>
<p><code>Imagine this scenario - with slightly contrived numbers:</code> <strong>An ideal world with a single CPU. No scheduling overhead, no I&#x2F;O overhead. Just keeping things simple.</strong></p>
<ul>
<li>You have 100 processes waiting for something.</li>
<li>When that “something” happens, each process will need 0.05 seconds of CPU time to do stuff in response.</li>
<li>When “something” does not happen, you have 0% CPU utilisation, and a queue length of 0. Basically stuff is just waiting. Life is good, and you’re merely wasting electrons and heating up the planet.</li>
<li>“something” happens. All 100 processes wake up. Your queue length jumps to 100, and your CPU is busy.</li>
<li>0.05 seconds later, your queue length is 99 as the first process has finished doing “stuff”. CPU is still busy.</li>
<li>After 0.1 seconds, your queue length is 98 as the 2nd process has finished doing “stuff”. CPU is still busy.</li>
<li>Every 0.05 your queue length drops by 1 as a process finishes. CPU remains busy.</li>
<li>After 5 seconds, all the processes have finished; CPU becomes idle again and your queue length is back to zero.</li>
<li><strong>Your CPU utilisation over the last 60 seconds is now: 5&#x2F;60 &#x3D; 8.33%. But your average queue length (&#x3D;load average) over the last 60 seconds will be about 4.2.</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">len:  100  99     98    97    ... 1      0     ...  0</span><br><span class="line">time: 0    0.05   0.1   0.15      4.95   5          59</span><br><span class="line"></span><br><span class="line">average = (0+0+...+1+2+3...+100)/(59/0.05+1) = 4.27</span><br></pre></td></tr></table></figure></li>
</ul>
<p>Looking at the 1-minute CPU utilisation alone (8.33%), you look good. But the 1-minute load average (4.2) shows that you have a performance bottleneck during that minute. Whether this is “bad” or not depends on whether you want it to be faster - do you need to respond to “something” happening more frequently than every 5 seconds?</p>
<p><strong>NOTE</strong></p>
<ul>
<li><code>Load average is always high for periburst load(many processes are ready to run at a time) which runs shortly while cpu uage is not so high.</code></li>
<li>Too many <code>D process</code> as a process in state D is in uninterruptible, it’ counted by load average as well.</li>
</ul>
<h1 id="useful-commands-and-performance-tools"><a href="#useful-commands-and-performance-tools" class="headerlink" title="useful commands and performance tools"></a>useful commands and performance tools</h1><p>To debug performance issue, there are lots of tools that we can use to help us identify the issue, but some of them are old tools, some of new, so here we only introduce new tools that’s are used today.</p>
<!-- more -->
<p><strong>Old tool</strong></p>
<ul>
<li>grpof</li>
<li>Oprofile</li>
</ul>
<p><strong>new tool</strong></p>
<ul>
<li>gperftools<br>gperftools is newer since 2007 developed by Google, it’s simpler, only from <mark>process view, stack of process</mark></li>
<li>perf<br>perf is already in kernel source tree(upstream) since since 2009, it’s complex, can show<br>more information from <mark>system-wide view</mark> it uses hardware counters to profile the application.<br>The result of this profiler are really precise and because it is not doing instrumentation of the code, it is really fast.</li>
</ul>
<p><strong>perf can check a process(stack from kernel to process stack) or check system(without given process id)</strong></p>
<h2 id="useful-commands"><a href="#useful-commands" class="headerlink" title="useful commands"></a>useful commands</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">show cpu load</span><br><span class="line">    Each running process either using or waiting for CPU resources adds 1 to the load average. So, if your system has a load of 5, five processes are either using or waiting for the CPU, the load number doesn’t mean too much. A computer might have a load of 0 one split-second, and a load of 5 the next split-second as several processes use the CPU. Even if you could see the load at any given time, that number would be basically meaningless. That’s why Unix-like systems don’t display the current load. They display the load average — an average of the computer’s load over several periods of time. This allows you to see how much work your computer has been performing.</span><br><span class="line"></span><br><span class="line">    # uptime</span><br><span class="line">    10:11:01 up 18:57,  4 users,  load average: 0.50, 2.13, 1.85</span><br><span class="line">    From left to right, these numbers show you the average load over the last one minute, the last five minutes, and the last fifteen minutes</span><br><span class="line"></span><br><span class="line">show how much time process runs in sys, user</span><br><span class="line"></span><br><span class="line">    Real time is wall clock time. (what we could measure with a stopwatch)</span><br><span class="line">    User time is the amount of time spend in user-mode within the process</span><br><span class="line">    Sys is the CPU time spend in the kernel within the process.</span><br><span class="line"></span><br><span class="line">    NOTE: real can be less than user if, it&#x27;s app is multi-thread or multi-process!!!</span><br><span class="line"></span><br><span class="line">    The rule of thumb is:</span><br><span class="line">    real &lt; user: The process is CPU bound and takes advantage of parallel execution on multiple cores/CPUs.</span><br><span class="line">    real ≈ user: The process is CPU bound and takes no advantage of parallel exeuction.</span><br><span class="line">    real &gt; user: The process is I/O bound. Execution on multiple cores would be of little to no advantage.</span><br><span class="line"></span><br><span class="line">    #time ls</span><br><span class="line">         share  windows</span><br><span class="line">         real    0m0.002s</span><br><span class="line">         user    0m0.001s</span><br><span class="line">         sys 0m0.001s</span><br><span class="line"></span><br><span class="line">show latency of RT linux kernel</span><br><span class="line"></span><br><span class="line">    #cyclictest</span><br><span class="line">    (git://git.kernel.org/pub/scm/utils/rt-tests/rt-tests.git)</span><br><span class="line"></span><br><span class="line">show slab info</span><br><span class="line"></span><br><span class="line">    #cat /proc/slabinfo</span><br><span class="line">    #slabtop</span><br><span class="line">        Active / Total Objects (% used)    : 133629 / 147300 (90.7%)</span><br><span class="line">        Active / Total Slabs (% used)      : 11492 / 11493 (100.0%)</span><br><span class="line">        Active / Total Caches (% used)     : 77 / 121 (63.6%)</span><br><span class="line">        Active / Total Size (% used)       : 41739.83K / 44081.89K (94.7%)</span><br><span class="line">        Minimum / Average / Maximum Object : 0.01K / 0.30K / 128.00K</span><br><span class="line"></span><br><span class="line">         OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME</span><br><span class="line">        44814  43159  96%    0.62K   7469        6     29876K ext3_inode_cache</span><br><span class="line">        36900  34614  93%    0.05K    492       75      1968K buffer_head</span><br><span class="line">        35213  33124  94%    0.16K   1531       23      6124K dentry_cache</span><br><span class="line">         7364   6463  87%    0.27K    526       14      2104K radix_tree_node</span><br><span class="line">         1280   1015  79%    0.25K     40       32       320K kmalloc-256  ---&gt; two pages for one slab</span><br><span class="line">    (Note, the management memory is not calculated!!!, but it&#x27;s small)</span><br><span class="line"></span><br><span class="line">    Each cache may have many slabs(empty, partial, full), each slab is one or multiple PAGE SIZE</span><br><span class="line">    (usually 4K for a PAGE SIZE)!</span><br><span class="line"></span><br><span class="line">    USE        = (ACTIVE/OBJS)*100/100</span><br><span class="line">    OBJS       = SLABS*(OBJ/SLAB)</span><br><span class="line">    OBJ/SLAB   = (4K*n)/OBJ_SIZE</span><br><span class="line">    CACHE SIZE = SLABS * (4K*n)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">show swap size used by each process</span><br><span class="line">    #smem</span><br><span class="line">      (RSS 656 mean 656K?)</span><br><span class="line">      PID User     Command                         Swap      USS      PSS      RSS</span><br><span class="line">     2516 rabbitmq sh -c /usr/lib/rabbitmq/bin        0       96      116      656</span><br><span class="line">     1451 lightdm  /bin/sh /usr/lib/lightdm/li        0      100      121      700</span><br><span class="line">     1130 root     /bin/sh -e /proc/self/fd/9         0      100      122      680</span><br><span class="line">     1157 root     /sbin/getty -8 38400 tty3          0      156      174      964</span><br><span class="line"></span><br><span class="line">    Show basic process information  smem</span><br><span class="line">    Show library-oriented view  smem -m</span><br><span class="line">    Show user-oriented view     smem -u</span><br><span class="line">    Show system view    smem -R 4G -K /path/to/vmlinux -w</span><br><span class="line">    Show totals and percentages     smem -t -p</span><br><span class="line">    Show different columns  smem -c &quot;name user pss&quot;</span><br><span class="line">    Sort by reverse RSS     smem -s rss -r</span><br><span class="line">    Show processes filtered by mapping  smem -M libxml</span><br><span class="line">    Show mappings filtered by process   smem -m -P [e]volution</span><br><span class="line">    Read data from capture tarball  smem --source capture.tar.gz</span><br><span class="line">    Show a bar chart labeled by pid     smem --bar pid -c &quot;pss uss&quot;</span><br><span class="line">    Show a pie chart of RSS labeled by name     smem --pie name -s rss</span><br><span class="line"></span><br><span class="line">Show memory usage by &#x27;free&#x27; command</span><br><span class="line"></span><br><span class="line">    $ free </span><br><span class="line">                  total        used        free      shared  buff/cache   available</span><br><span class="line">    Mem:       24687560    11825536     8579812      258488     4282212    12299492</span><br><span class="line">    Swap:      16774140           0    16774140</span><br><span class="line"></span><br><span class="line">    total== 11825536 + 8579812 + 4282212 == 24687560</span><br><span class="line">    available = 8579812 + part of(buff/cache which is not used by OS)</span><br><span class="line"></span><br><span class="line">    total: Your total (physical) RAM (excluding a small bit that the kernel permanently reserves for itself at startup);</span><br><span class="line">    used: memory in use by the OS(calculate apps, buffers, caches)</span><br><span class="line">    free: memory not in use.</span><br><span class="line"></span><br><span class="line">    total = used + free + buff/cache</span><br><span class="line"></span><br><span class="line">    shared /buff/cache: This shows memory usage for specific purposes</span><br><span class="line">    (write data to disk, buffer is used, which cache is used for storing data read from disk in memory)</span><br><span class="line"></span><br><span class="line">    The last line (Swap:) gives information about swap space usage (i.e. memory contents that have been temporarily moved to disk).</span><br><span class="line"></span><br><span class="line">    To actually understand what the numbers mean, you need a bit of background about the virtual memory (VM) subsystem in Linux.</span><br><span class="line">    Just a short version: Linux (like most modern OS) will always try to use free RAM for caching stuff, so Mem: free will almost always be very low.</span><br><span class="line">    caches will be freed automatically if memory gets scarce, so they do not really matter.</span><br><span class="line"></span><br><span class="line">Inside exec()</span><br><span class="line"></span><br><span class="line">    In computing, exec is a functionality of an operating system that runs an executable file in the context of an already existing process,</span><br><span class="line">    replacing the previous executable. This act is also referred to as an overlay. It is especially important in Unix-like systems, although exists elsewhere.</span><br><span class="line">   As a new process is not created, the process identifier (PID) does not change,</span><br><span class="line">   but the machine code, data, heap, and stack of the process are replaced by those of the new program.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">====================================================SAR===================================================================================</span><br><span class="line">sar(System Activity Report)： Show system activity information, its gives more details about cpu, memory, interrupt, io, power, network etc</span><br><span class="line">But you can also check other commands for specific resource from below section</span><br><span class="line"></span><br><span class="line">    # -B is more general including(swap process memory + disk io)</span><br><span class="line">    # sar -B 5 </span><br><span class="line">    Linux 3.10.0-1160.el7.x86_64 (dev) 	10/12/2022 	_x86_64_	(16 CPU)</span><br><span class="line"></span><br><span class="line">    05:14:19 PM  pgpgin/s pgpgout/s   fault/s  majflt/s  pgfree/s pgscank/s pgscand/s pgsteal/s    %vmeff</span><br><span class="line">    05:14:24 PM      0.00  31948.80     10.00      0.00    136.20      0.00      0.00      0.00      0.00</span><br><span class="line">    05:14:29 PM      0.00 236544.00     10.80      0.00     57.40      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">    # -W is about swap of process memory(swap process page to disk when there is not engouh memory)</span><br><span class="line">    #sar -W 5</span><br><span class="line">    Linux 3.10.0-1160.el7.x86_64 (dev) 	10/12/2022 	_x86_64_	(16 CPU)</span><br><span class="line">    </span><br><span class="line">    05:14:43 PM  pswpin/s pswpout/s</span><br><span class="line">    05:14:48 PM      0.00      0.00</span><br><span class="line">    05:14:53 PM      0.00      0.00</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    Report I/O and transfer rate statistics</span><br><span class="line">    # sar -b 5 </span><br><span class="line">    Linux 3.10.0-1160.el7.x86_64 (dev)      10/22/2021      _x86_64_        (8 CPU)</span><br><span class="line"></span><br><span class="line">    05:34:02 PM       tps      rtps      wtps   bread/s   bwrtn/s</span><br><span class="line">    05:34:07 PM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:34:12 PM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">    Report activity for each block device</span><br><span class="line">    # sar -d 5 </span><br><span class="line">    Linux 3.10.0-1160.el7.x86_64 (dev)      10/22/2021      _x86_64_        (8 CPU)</span><br><span class="line"></span><br><span class="line">    05:34:20 PM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util</span><br><span class="line">    05:34:25 PM    dev8-0      0.20      0.00      6.40     32.00      0.00      1.00      1.00      0.02</span><br><span class="line">    05:34:25 PM  dev253-0      0.20      0.00      6.40     32.00      0.00      1.00      1.00      0.02</span><br><span class="line">    05:34:25 PM  dev253-1      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:34:25 PM  dev253-2      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">    show interrupt per 5s</span><br><span class="line">    # sar -I ALL 5</span><br><span class="line">    Linux 3.10.0-1160.el7.x86_64 (dev)      10/22/2021      _x86_64_        (8 CPU)</span><br><span class="line"></span><br><span class="line">    05:37:36 PM      INTR    intr/s</span><br><span class="line">    05:37:41 PM         0      0.00</span><br><span class="line">    05:37:41 PM         1      0.00</span><br><span class="line">    05:37:41 PM         2      0.00</span><br><span class="line">    05:37:41 PM         3      0.00</span><br><span class="line">    05:37:41 PM         4      0.00</span><br><span class="line">    05:37:41 PM         5      0.00</span><br><span class="line">    05:37:41 PM         6      0.00</span><br><span class="line">    05:37:41 PM         7      0.00</span><br><span class="line">    05:37:41 PM         8      0.00</span><br><span class="line">    05:37:41 PM         9      0.00</span><br><span class="line">    05:37:41 PM        10      0.00</span><br><span class="line">    05:37:41 PM        11      0.00</span><br><span class="line">    05:37:41 PM        12      0.00</span><br><span class="line">    05:37:41 PM        13      0.00</span><br><span class="line">    05:37:41 PM        14      0.80</span><br><span class="line">    05:37:41 PM        15      0.00</span><br><span class="line"></span><br><span class="line">    show power management</span><br><span class="line">    $ ar -m ALL 10</span><br><span class="line">    Linux 3.10.0-327.36.4.el7.x86_64 (A04-R08-I138-47-91TYB72.JCLOUD.COM)   10/22/2021      _x86_64_        (32 CPU)</span><br><span class="line"></span><br><span class="line">    05:40:01 PM     CPU       MHz</span><br><span class="line">    05:40:11 PM     all   1258.82</span><br><span class="line"></span><br><span class="line">    05:40:01 PM    TEMP      degC     %temp               DEVICE</span><br><span class="line">    05:40:11 PM       1     43.00     55.84    coretemp-isa-0000</span><br><span class="line">    05:40:11 PM       2     38.00     49.35    coretemp-isa-0000</span><br><span class="line">    05:40:11 PM       3     37.00     48.05    coretemp-isa-0000</span><br><span class="line">    05:40:11 PM       4     34.00     44.16    coretemp-isa-0000</span><br><span class="line">    05:40:11 PM       5     38.00     49.35    coretemp-isa-0000</span><br><span class="line">    05:40:11 PM       6     33.00     42.86    coretemp-isa-0000</span><br><span class="line">    05:40:11 PM       7     34.00     44.16    coretemp-isa-0000</span><br><span class="line">    05:40:11 PM       8     37.00     48.05    coretemp-isa-0000</span><br><span class="line">    05:40:11 PM       9     35.00     45.45    coretemp-isa-0000</span><br><span class="line">    05:40:11 PM      10     44.00     57.14    coretemp-isa-0001</span><br><span class="line">    05:40:11 PM      11     36.00     46.75    coretemp-isa-0001</span><br><span class="line">    05:40:11 PM      12     36.00     46.75    coretemp-isa-0001</span><br><span class="line">    05:40:11 PM      13     37.00     48.05    coretemp-isa-0001</span><br><span class="line">    05:40:11 PM      14     37.00     48.05    coretemp-isa-0001</span><br><span class="line">    05:40:11 PM      15     34.00     44.16    coretemp-isa-0001</span><br><span class="line">    05:40:11 PM      16     36.00     46.75    coretemp-isa-0001</span><br><span class="line">    05:40:11 PM      17     34.00     44.16    coretemp-isa-0001</span><br><span class="line">    05:40:11 PM      18     34.00     44.16    coretemp-isa-0001</span><br><span class="line"></span><br><span class="line">    05:40:01 PM     BUS  idvendor    idprod  maxpower                manufact                                         product</span><br><span class="line">    05:40:11 PM       1      8087      800a         0                                                                        </span><br><span class="line">    05:40:11 PM       2      8087      8002         0                                                                        </span><br><span class="line">    05:40:11 PM       1      413c      a001       200         no manufacturer                                  Gadget USB HUB</span><br><span class="line"></span><br><span class="line">    show network stats, lots of fields, only list some</span><br><span class="line">    # sar -n ALL 10</span><br><span class="line">    Linux 3.10.0-327.36.4.el7.x86_64 (A04-R08-I138-47-91TYB72.JCLOUD.COM)   10/22/2021      _x86_64_        (32 CPU)</span><br><span class="line"></span><br><span class="line">    05:43:15 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">    05:43:25 PM tap_metadata      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM vxlan_sys_4789      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM       br0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM tap_proxy_ns      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM ovs-system      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM tap_proxy      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM      eth0      2.10      2.00      0.23      0.19      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM        lo      2.00      2.00      0.79      0.79      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM       em2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM       em4      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM       em3      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">    05:43:15 PM     IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s</span><br><span class="line">    05:43:25 PM tap_metadata      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM vxlan_sys_4789      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM       br0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM tap_proxy_ns      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM ovs-system      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM tap_proxy      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM      eth0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM       em2      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM       em4      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM       em3      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">    05:43:25 PM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">    Report cpu queue length and load averages</span><br><span class="line">    # sar -P ALL -q 10</span><br><span class="line">    Linux 3.10.0-327.36.4.el7.x86_64 (A04-R08-I138-47-91TYB72.JCLOUD.COM)   10/22/2021      _x86_64_        (32 CPU)</span><br><span class="line"></span><br><span class="line">    05:48:32 PM   runq-sz  plist-sz   ldavg-1   ldavg-5  ldavg-15   blocked</span><br><span class="line">    05:48:42 PM         0      1069      0.43      0.46      0.49         0</span><br><span class="line">    </span><br><span class="line">    Report memory utilization statistics</span><br><span class="line">    # sar -r 10</span><br><span class="line">    Linux 3.10.0-327.36.4.el7.x86_64 (A04-R08-I138-47-91TYB72.JCLOUD.COM)   10/22/2021      _x86_64_        (32 CPU)</span><br><span class="line"></span><br><span class="line">    05:46:25 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty</span><br><span class="line">    05:46:35 PM 119478308  12269620      9.31      1868   9411160   5926572      3.99   4968572   5430432      1560</span><br><span class="line"></span><br><span class="line">    Report CPU utilization</span><br><span class="line">    # sar -P ALL -u 10</span><br><span class="line">    Linux 3.10.0-327.36.4.el7.x86_64 (A04-R08-I138-47-91TYB72.JCLOUD.COM)   10/22/2021      _x86_64_        (32 CPU)</span><br><span class="line"></span><br><span class="line">    05:47:32 PM     CPU     %user     %nice   %system   %iowait    %steal     %idle</span><br><span class="line">    05:47:42 PM     all      1.39      0.00      0.40      0.00      0.00     98.20</span><br><span class="line">    05:47:42 PM       0     40.49      0.00      0.00      0.00      0.00     59.51</span><br><span class="line">    05:47:42 PM       1      0.00      0.00      0.30      0.00      0.00     99.70</span><br><span class="line">    05:47:42 PM       2      0.41      0.00      1.32      0.00      0.00     98.28</span><br><span class="line">    05:47:42 PM       3      0.10      0.00      0.20      0.00      0.00     99.70</span><br><span class="line">    05:47:42 PM       4      0.30      0.00      0.80      0.00      0.00     98.89</span><br><span class="line">    05:47:42 PM       5      0.20      0.00      0.40      0.00      0.00     99.40</span><br><span class="line">    05:47:42 PM       6      0.20      0.00      0.40      0.00      0.00     99.40</span><br><span class="line">    05:47:42 PM       7      0.00      0.00      0.20      0.00      0.00     99.80</span><br><span class="line">    05:47:42 PM       8      0.70      0.00      0.90      0.00      0.00     98.39</span><br><span class="line"></span><br><span class="line">    Report task creation and system switching activity</span><br><span class="line">    # sar -w 10</span><br><span class="line">    Linux 3.10.0-327.36.4.el7.x86_64 (A04-R08-I138-47-91TYB72.JCLOUD.COM)   10/22/2021      _x86_64_        (32 CPU)</span><br><span class="line"></span><br><span class="line">    05:48:56 PM    proc/s   cswch/s</span><br><span class="line">    05:49:06 PM      2.30  12558.70</span><br><span class="line">====================================================SAR===================================================================================</span><br><span class="line"></span><br><span class="line">Show CPUS stats</span><br><span class="line">    CPU utilization stats runs on user, sys, virtual processor(vm)</span><br><span class="line">    # mpstat -P ALL -u</span><br><span class="line">    04:38:08 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle</span><br><span class="line">    04:38:08 PM  all    7.03    0.06    2.89    0.01    0.00    0.00    0.00    8.28    0.00   81.73</span><br><span class="line">    04:38:08 PM    0    0.88    0.08    3.26    0.01    0.00    0.19    0.00   10.02    0.00   85.56</span><br><span class="line">    04:38:08 PM    1    0.89    0.04    3.30    0.01    0.00    0.02    0.00    9.47    0.00   86.28</span><br><span class="line">    04:38:08 PM    2    0.83    0.08    3.15    0.01    0.00    0.01    0.00   10.15    0.00   85.78</span><br><span class="line">    04:38:08 PM    3    0.82    0.04    3.15    0.01    0.00    0.00    0.00    9.61    0.00   86.39</span><br><span class="line">    04:38:08 PM    4    1.03    0.07    4.59    0.01    0.00    0.01    0.00   12.51    0.00   81.78</span><br><span class="line">    04:38:08 PM    5    0.92    0.04    3.22    0.01    0.00    0.00    0.00    9.58    0.00   86.23</span><br><span class="line">    04:38:08 PM    6    1.10    0.07    4.63    0.01    0.00    0.00    0.00   12.52    0.00   81.66</span><br><span class="line">    04:38:08 PM    7    0.83    0.05    3.42    0.01    0.00    0.00    0.00   10.44    0.00   85.25</span><br><span class="line">    04:38:08 PM    8   99.75    0.00    0.25    0.00    0.00    0.00    0.00    0.00    0.00    0.00</span><br><span class="line"></span><br><span class="line">    CPU soft irq</span><br><span class="line">    # mpstat -I SCPU</span><br><span class="line">    Linux 3.10.0-693.21.4.el7.x86_64 (A01-R15-I124-40-CCK4HP2.JCLOUD.COM)   10/22/2021      _x86_64_        (64 CPU)</span><br><span class="line"></span><br><span class="line">    04:39:57 PM  CPU       HI/s    TIMER/s   NET_TX/s   NET_RX/s    BLOCK/s BLOCK_IOPOLL/s  TASKLET/s    SCHED/s  HRTIMER/s      RCU/s</span><br><span class="line">    04:39:57 PM    0       0.00      54.90       0.20       2.42       0.00       0.00       0.05      12.35       0.00      10.65</span><br><span class="line">    04:39:57 PM    1       0.00      41.11       0.00       0.48       0.04       0.00       7.10      43.85       0.00       7.03</span><br><span class="line">    04:39:57 PM    2       0.00      60.01       0.01      14.90       0.00       0.00       0.57      59.44       0.00      10.80</span><br><span class="line">    04:39:57 PM    3       0.00      33.81       0.00       0.50       0.04       0.00       0.00      52.79       0.00       3.72</span><br><span class="line">    04:39:57 PM    4       0.00      40.35       0.01      17.83       0.00       0.00       0.75       6.86       0.00      23.19</span><br><span class="line">    04:39:57 PM    5       0.00      44.60       0.00       0.51       0.04       0.00       0.00      53.62       0.00       7.76</span><br><span class="line">    04:39:57 PM    6       0.00      44.92       0.01      12.48       0.00       0.00       0.51       7.00       0.00      24.59</span><br><span class="line">    04:39:57 PM    7       0.00      58.52       0.00       0.46       0.04       0.00       0.00      57.85       0.00      12.73</span><br><span class="line">    04:39:57 PM    8       0.00      33.03       0.00       0.00       0.00       0.00       0.00       0.00       0.00      58.50</span><br><span class="line"></span><br><span class="line">Show CPU live stats</span><br><span class="line">    # top</span><br><span class="line">    top - 16:45:28 up 771 days,  3:16,  1 user,  load average: 6.66, 7.24, 6.54</span><br><span class="line">    Tasks: 670 total,   9 running, 661 sleeping,   0 stopped,   0 zombie</span><br><span class="line">    %Cpu(s):  9.7 us,  1.6 sy,  0.1 ni, 88.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">    KiB Mem : 26379142+total,  3811248 free, 23686681+used, 23113348 buff/cache</span><br><span class="line">    KiB Swap: 16777212 total, 16691312 free,    85900 used. 25565136 avail Mem</span><br><span class="line"></span><br><span class="line">    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line">    127796 root      10 -10  0.105t 573032  20444 S 403.6  0.2  42365,18 vswitchd</span><br><span class="line">    131315 root      20   0 9188560  87436   5940 S 108.6  0.0 668887:05 qemu-kvm</span><br><span class="line">    113257 root      20   0 9220320  77628   5916 S  78.8  0.0 300804:39 qemu-kvm</span><br><span class="line">    69578 root      20   0 9043128  66088   3640 S  18.2  0.0   2199:03 qemu-system-x86</span><br><span class="line">    123753 root      20   0 9039996  63892   3604 S  15.9  0.0 764:21.77 qemu-system-x86</span><br><span class="line">    113084 root      20   0 9074688  68036   1916 S  12.3  0.0 170215:57 qemu-system-x86</span><br><span class="line">    99040 root      20   0 16.647g  65140   1900 S   9.6  0.0 158111:53 qemu-system-x86</span><br><span class="line">    133933 root      20   0 4836392  64328   3648 S   8.6  0.0 381:15.29 qemu-system-x86</span><br><span class="line">    92403 root      20   0 4825240  62916   3308 S   7.3  0.0  21040:53 qemu-system-x86</span><br><span class="line">    100018 root      20   0 3471696   5216   2616 S   7.0  0.0   8384:57 logd</span><br><span class="line"></span><br><span class="line">    # htop</span><br><span class="line"></span><br><span class="line">show live virtual memory usage</span><br><span class="line">    show stats per 2s, actuall, it also shows io, system, cpu as well</span><br><span class="line">    $ vmstat  -n 2</span><br><span class="line">    procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line">    r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line">    5  4  85900 4185664   4396 22772168    0    0     1    91    0    0 15  3 82  0  0</span><br><span class="line">    6  0  85900 4181612   4396 22772580    0    0    64   479 55060 82145  8  1 91  0  0</span><br><span class="line">    8  0  85900 4184968   4396 22772636    0    0    96    98 56364 87759  8  1 91  0  0</span><br><span class="line">    8  0  85900 4183828   4396 22772936    0    0    96   152 58835 88482  9  1 90  0  0</span><br><span class="line">    6  0  85900 4180524   4396 22772920    0    0     0   320 58749 94072  9  1 90  0  0</span><br><span class="line">    5  0  85900 4184580   4396 22773588    0    0     0   234 67631 111630  9  2 89  0  0</span><br><span class="line"></span><br><span class="line">show io statistics, most used for which disk has high io await.</span><br><span class="line">    the io wait of the whole system(96.0%wa)</span><br><span class="line">    # top</span><br><span class="line">    top - 14:31:20 up 35 min, 4 users, load average: 2.25, 1.74, 1.68</span><br><span class="line">    Tasks: 71 total, 1 running, 70 sleeping, 0 stopped, 0 zombie</span><br><span class="line">    Cpu(s): 2.3%us, 1.7%sy, 0.0%ni, 0.0%id, 96.0%wa, 0.0%hi, 0.0%si, 0.0%st</span><br><span class="line">    Mem: 245440k total, 241004k used, 4436k free, 496k buffers</span><br><span class="line">    Swap: 409596k total, 5436k used, 404160k free, 182812k cached</span><br><span class="line"></span><br><span class="line">    show iostat per 10s of each block device(check which block device has high io wait)</span><br><span class="line">    # sar -d 5</span><br><span class="line">    # iostat -txz 10</span><br><span class="line">    Linux 3.10.0-693.21.4.el7.x86_64 (A01-R15-I124-40-CCK4HP2.JCLOUD.COM)   10/22/2021      _x86_64_        (64 CPU)</span><br><span class="line"></span><br><span class="line">    10/22/2021 05:14:10 PM</span><br><span class="line">    avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">            15.31    0.06    2.89    0.01    0.00   81.73</span><br><span class="line"></span><br><span class="line">    Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">    nvme0n1           0.00     0.06    1.06   47.46    43.69  4897.74   203.70     0.01    0.25    0.26    0.25   0.06   0.29</span><br><span class="line">    sda               0.00     0.03    0.00    0.73     0.07     7.51    20.56     0.01   19.20    6.80   19.27   3.83   0.28</span><br><span class="line">    nb100             0.00     0.01    0.29    7.33    36.40   545.36   152.62     0.02    3.25    9.77    2.99   1.07   0.82</span><br><span class="line">    nb101             0.00     0.00    0.00    1.76     0.03    14.69    16.69     0.00    0.94    1.29    0.94   0.29   0.05</span><br><span class="line">    nb102             0.00     0.00    0.00    6.72     0.01   132.59    39.46     0.01    1.18    0.70    1.18   0.28   0.19</span><br><span class="line">    nb103             0.00     0.00    0.00    0.55     0.02     7.14    25.97     0.00    0.86    0.54    0.86   0.46   0.03</span><br><span class="line">    nb104             0.00     0.00    0.00    0.31     0.01    10.68    68.74     0.00    1.45    0.50    1.45   0.43   0.01</span><br><span class="line">    nb105             0.00     0.00    0.00    1.29     0.02    78.13   121.00     0.00    3.56    0.62    3.56   0.50   0.06</span><br><span class="line">    nb106             0.00     0.00    0.01    0.71     0.83    40.81   116.51     0.00    1.19    0.57    1.19   0.69   0.05</span><br><span class="line">    nb107             0.00     0.00    0.00    0.17     0.01     1.37    16.55     0.00    1.21    8.04    1.20   0.39   0.01</span><br><span class="line">    nb108             0.00     0.00    0.00    0.17     0.00     1.29    15.10     0.00    0.90    0.53    0.90   0.44   0.01</span><br><span class="line">    nb109             0.00     0.00    0.00    0.00     0.00     0.04    60.20     0.00   42.15    0.42   43.57   0.46   0.00</span><br><span class="line"></span><br><span class="line">    show io per process, which process is writing high io</span><br><span class="line">    #iotop</span><br><span class="line">    Total DISK READ :       0.00 B/s | Total DISK WRITE :       0.00 B/s</span><br><span class="line">    Actual DISK READ:       0.00 B/s | Actual DISK WRITE:       0.00 B/s</span><br><span class="line">    TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&gt;    COMMAND                                                                                                                                          </span><br><span class="line">    17391 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.02 % [kworker/6:0]</span><br><span class="line">    16896 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % python -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-0fe83e4c-ccd4-49f4-ae7e-4b07fabb2dc3.json</span><br><span class="line">        1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % systemd --switched-root --system --deserialize 22</span><br><span class="line">        2 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kthreadd]</span><br><span class="line">        4 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/0:0H]</span><br><span class="line">        6 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/0]</span><br><span class="line">        7 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/0]</span><br><span class="line">        8 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_bh]</span><br><span class="line">        9 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_sched]</span><br><span class="line"></span><br><span class="line">show interface statistics</span><br><span class="line">    show stats of ifaces</span><br><span class="line">    # ifstat</span><br><span class="line">    #kernel</span><br><span class="line">    Interface        RX Pkts/Rate    TX Pkts/Rate    RX Data/Rate    TX Data/Rate  </span><br><span class="line">                    RX Errs/Drop    TX Errs/Drop    RX Over/Rate    TX Coll/Rate  </span><br><span class="line">    lo                     0 0             0 0             0 0             0 0      </span><br><span class="line">                        0 0             0 0             0 0             0 0      </span><br><span class="line">    enp0s3                 8 0             6 0           560 0          1424 0      </span><br><span class="line">                        0 0             0 0             0 0             0 0      </span><br><span class="line">    docker0                0 0             0 0             0 0             0 0      </span><br><span class="line">                        0 0             0 0             0 0             0 0      </span><br><span class="line">    vethbedf2bf            0 0             0 0             0 0             0 0      </span><br><span class="line">                        0 0             0 0             0 0             0 0    </span><br><span class="line"></span><br><span class="line">    # live stats on each interface                    </span><br><span class="line">    #iftop</span><br><span class="line"></span><br><span class="line">    # live stats on each process which has network io</span><br><span class="line">    # nethogs</span><br><span class="line">    NetHogs version 0.8.5</span><br><span class="line"></span><br><span class="line">        PID USER     PROGRAM             DEV        SENT      RECEIVED       </span><br><span class="line">    13337 root     sshd: root@pts/2    enp0s3      0.218       0.186 KB/sec      </span><br><span class="line">    ?     root     unknown TCP                     0.000       0.000 KB/sec</span><br><span class="line">    TOTAL                                          0.218       0.186 KB/sec</span><br><span class="line"></span><br><span class="line">    show details about interface like config, stats etc</span><br><span class="line">    # ethtool -h</span><br><span class="line">    ethtool -g|--show-ring DEVNAME	Query RX/TX ring parameters</span><br><span class="line">    ethtool -k|--show-features|--show-offload DEVNAME	Get state of protocol offload and other features</span><br><span class="line">    ethtool -i|--driver DEVNAME	Show driver information</span><br><span class="line">    ethtool -S|--statistics DEVNAME	Show adapter statistics</span><br><span class="line">    ethtool -n|-u|--show-nfc|--show-ntuple DEVNAME	Show Rx network flow classification options or rules</span><br><span class="line">    ethtool -x|--show-rxfh-indir|--show-rxfh DEVNAME	Show Rx flow hash indirection and/or hash key</span><br><span class="line"></span><br><span class="line">show power management</span><br><span class="line">    show power used by each process live</span><br><span class="line">    # powertop</span><br><span class="line">    PowerTOP v2.9     Overview   Idle stats   Frequency stats   Device stats   Tunables                                     </span><br><span class="line">    Summary: 72.3 wakeups/second,  0.0 GPU ops/seconds, 0.0 VFS ops/sec and 0.3% CPU use</span><br><span class="line"></span><br><span class="line">                    Usage       Events/s    Category       Description</span><br><span class="line">                122.3 µs/s      20.0        Process        [PID 460] [xfsaild/dm-0]</span><br><span class="line">                72.8 µs/s       9.5        Timer          tick_sched_timer</span><br><span class="line">                116.2 µs/s       6.7        Timer          hrtimer_wakeup</span><br><span class="line">                93.0 µs/s       5.7        Process        [PID 1084] /usr/bin/containerd</span><br><span class="line">                63.7 µs/s       5.7        Process        [PID 9] [rcu_sched]</span><br><span class="line">                632.7 µs/s       4.8        Process        [PID 1049] /home/data/Anaconda3/bin/python /home/data/Anaconda3/bin/jupyter-notebook -y --no-browser --allow-root --ip=10.0.2.1</span><br><span class="line">                61.6 µs/s       4.8        Process        [PID 1082] /usr/bin/containerd</span><br><span class="line">                34.9 µs/s       2.9        Interrupt      [3] net_rx(softirq)</span><br><span class="line">                183.8 µs/s       1.9        Interrupt      [7] sched(softirq)</span><br><span class="line">                239.2 µs/s       1.0        kWork          e1000_watchdog</span><br><span class="line"></span><br><span class="line">Benchmark tools</span><br><span class="line"></span><br><span class="line">    for operation function</span><br><span class="line">    #apt-get install lmbench</span><br><span class="line"></span><br><span class="line">    Layer 4 Throughput using NetPerf and iPerf, two open source network performance benchmark tools that support both UDP and TCP protocols. Each tool provides in addition other information:</span><br><span class="line">    NetPerf for example provides tests for end-to-end latency (round-trip times or RTT) and is a good replacement for Ping</span><br><span class="line"></span><br><span class="line">    iPerf provides packet loss and delay jitter, useful to troubleshoot network performance.</span><br><span class="line"></span><br><span class="line">    for network, test the network between client(netperf) and server(netserver)</span><br><span class="line"></span><br><span class="line">    server side</span><br><span class="line">    #netserver</span><br><span class="line"></span><br><span class="line">    client side with testing 300s, or never stop(-l 0)</span><br><span class="line">    #netperf -H $server -l 300 -t TCP_STREAM</span><br><span class="line"></span><br><span class="line">    server side</span><br><span class="line">    #iperf3 --server --interval 30</span><br><span class="line">    client side</span><br><span class="line">    #iperf3 --client $server --time 300 --interval 30</span><br></pre></td></tr></table></figure>

<h2 id="check-bottleneck-call-graph"><a href="#check-bottleneck-call-graph" class="headerlink" title="check bottleneck, call graph"></a>check bottleneck, call graph</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br><span class="line"></span><br><span class="line">Don&#x27;t use gprof which is old since 198x</span><br><span class="line"></span><br><span class="line">Oprofile is old still release one version each year since 2002 and it uses the same backend</span><br><span class="line">as &#x27;perf&#x27; does, so can give almost the same output with &#x27;perf&#x27; but the Community recommend</span><br><span class="line">&#x27;perf&#x27; and intend to replace it</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">gperftools is newer since 2007 developed by Google, it&#x27;s simpler, only from process view</span><br><span class="line"></span><br><span class="line">perf is already in kernel source tree(upstream) since since 2009, it&#x27;s complex, can show</span><br><span class="line">more information from system-wide view!!!!!!!!!!!!!!! it uses hardware counters to profile the application.</span><br><span class="line">The result of this profiler are really precise and</span><br><span class="line">because it is not doing instrumentation of the code, it is really fast.</span><br><span class="line"></span><br><span class="line">gperftools and perf are two good choices nowadays!!!!!!!!!!!</span><br><span class="line"></span><br><span class="line">++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br></pre></td></tr></table></figure>

<h3 id="gperftools-great-perf-tools-originally-from-google-performance-tool-is-package-name"><a href="#gperftools-great-perf-tools-originally-from-google-performance-tool-is-package-name" class="headerlink" title="gperftools(great perf tools, originally from google performance tool, is package name)"></a>gperftools(great perf tools, originally from google performance tool, is package name)</h3><p><a target="_blank" rel="noopener" href="https://github.com/gperftools/gperftools">gperftools</a> is a collection of a high-performance multi-threaded malloc() implementation, plus some pretty nifty performance analysis tools.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Ubuntu18</span><br><span class="line">#apt-get install google-perftools graphviz libgoogle-perftools-dev</span><br><span class="line">Centos7</span><br><span class="line">$ yum install -y pprof gperftools-devel</span><br><span class="line"></span><br><span class="line">Usage</span><br><span class="line">    CPUPROFILE:(check which function or line take much time) NO track forked child!!!</span><br><span class="line"></span><br><span class="line">        As gperftools provides tcmalloc, heap checker, heap profiler and cpu profiler</span><br><span class="line">        (heap checker, heap profiler are in &#x27;-ltcmalloc&#x27;</span><br><span class="line">         cpu profiler &#x27;-lprofiler&#x27;</span><br><span class="line">         google-pprof is used to analysis the profile file)</span><br><span class="line"></span><br><span class="line">        There are two ways to use gperftools, one is to compile it within your program</span><br><span class="line">        the other is to used PRELOAD and set env(use the first way always!)</span><br><span class="line"></span><br><span class="line">        Generate profile file</span><br><span class="line">            a. Compile it within your program</span><br><span class="line"></span><br><span class="line">                #include &lt;gperftools/profiler.h&gt;</span><br><span class="line">                #include &lt;stdio.h&gt;</span><br><span class="line">                #include &lt;stdlib.h&gt;</span><br><span class="line">                void func1() &#123;</span><br><span class="line">                    int i = 0;</span><br><span class="line">                    while (i &lt; 100000) &#123;</span><br><span class="line">                        ++i;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                void func2() &#123;</span><br><span class="line">                    int i = 0;</span><br><span class="line">                    while (i &lt; 200000) &#123;</span><br><span class="line">                        ++i;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                void func3() &#123;</span><br><span class="line">                    int i = 0;</span><br><span class="line">                    for (i = 0; i &lt; 1000; ++i) &#123;</span><br><span class="line">                        func1();</span><br><span class="line">                        func2();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                int main()&#123;</span><br><span class="line">                    ProfilerStart(&quot;my.prof&quot;);</span><br><span class="line">                    func3();</span><br><span class="line">                    ProfilerStop();</span><br><span class="line">                    return 0;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">               # gcc -o test  test.c -g -Wall -lprofiler</span><br><span class="line"></span><br><span class="line">               This way(set CPUPROFILE) will do CPU profile definitely!!!, no switch</span><br><span class="line">               #CPUPROFILE_FREQUENCY=100 ./test</span><br><span class="line">               (100 samples per second, default value)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            b. Use PRELOAD (not recommended!!!!) without recompiling!!!!!</span><br><span class="line">                #export LD_PRELOAD=/usr/lib64/libprofiler.so</span><br><span class="line"></span><br><span class="line">                /*turn on cpu profile during whole life*/</span><br><span class="line">                #env CPUPROFILE=my.prof ./test</span><br><span class="line">    </span><br><span class="line">            -------------------------------------------------------------------------</span><br><span class="line">            | For a daemon process, run it forground!!! not a daemon for profiling. |</span><br><span class="line">            -------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">        ---------------------------------------------------------------------------</span><br><span class="line">        Analyze the profile file( take care of the first three columns)</span><br><span class="line">        to see which function or lines consume more CPU time!!!!!!!!!!</span><br><span class="line">        ---------------------------------------------------------------------------</span><br><span class="line">            See which function takes much time</span><br><span class="line">            root@ubuntu:~# google-pprof --text ./test my.prof</span><br><span class="line">            OR</span><br><span class="line">            root@centos:~# pprof --text ./test my.prof</span><br><span class="line"></span><br><span class="line">            Using local file ./test. (test is the program)</span><br><span class="line">            Using local file my.prof.(my.prof is the data collected before)</span><br><span class="line">            Removing killpg from all stack traces.</span><br><span class="line">            Total: 71 samples</span><br><span class="line">                  53                74.6%            74.6%          53  74.6% func2</span><br><span class="line">                  18                25.4%           100.0%          18  25.4% func1</span><br><span class="line">                   0                 0.0%           100.0%          71 100.0% __libc_start_main</span><br><span class="line">                   0                 0.0%           100.0%          71 100.0% _start</span><br><span class="line">                   0                 0.0%           100.0%          71 100.0% func3</span><br><span class="line">                   0                 0.0%           100.0%          71 100.0% main</span><br><span class="line"></span><br><span class="line">            column meanings</span><br><span class="line">            1. Number of profiling samples in this function</span><br><span class="line">            2. Percentage of profiling samples in this function</span><br><span class="line">            3. Percentage of profiling samples in the functions printed so far</span><br><span class="line">            4. Number of profiling samples in this function and its callees</span><br><span class="line">            5. Percentage of profiling samples in this function and its callees</span><br><span class="line">            6. Function name </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            if you perf to run, from system view, you will get</span><br><span class="line"></span><br><span class="line">            $perf record ./test</span><br><span class="line">            $perf report</span><br><span class="line">            65.73%  test     test              [.] func2</span><br><span class="line">            33.68%  test     test              [.] func1</span><br><span class="line">            0.16%  test     [kernel.vmlinux]  [k] native_write_msr_safe</span><br><span class="line">            0.06%  test     [kernel.vmlinux]  [k] x86_pmu_enable</span><br><span class="line">            0.05%  test     [kernel.vmlinux]  [k] __intel_pmu_disable_all</span><br><span class="line">            0.05%  test     libc-2.17.so      [.] __GI___dl_iterate_phdr</span><br><span class="line">            0.00%  test     [kernel.vmlinux]  [k] __do_page_fault</span><br><span class="line">            0.00%  test     libc-2.17.so      [.] __memset_sse2</span><br><span class="line">            0.00%  test     [kernel.vmlinux]  [k] lapic_next_deadline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            See which line takes much time, you have to build test with -g</span><br><span class="line">            root@ubuntu:~#google-pprof --lines --text ./test my.prof</span><br><span class="line">            OR</span><br><span class="line">            root@centos:~#pprof --lines --text ./test my.prof</span><br><span class="line"></span><br><span class="line">            Using local file ./test.</span><br><span class="line">            Using local file my.prof.</span><br><span class="line">            Removing killpg from all stack traces.</span><br><span class="line">            Total: 71 samples</span><br><span class="line">                  37  52.1%  52.1%       37  52.1% func2 /root/test.c:12 (discriminator 1)</span><br><span class="line">                  22  31.0%  83.1%       22  31.0% func1 /root/test.c:6 (discriminator 1)</span><br><span class="line">                  11  15.5%  98.6%       13  18.3% func2 /root/test.c:13</span><br><span class="line">                   1   1.4% 100.0%        1   1.4% func1 /root/test.c:7</span><br><span class="line">                   0   0.0% 100.0%       71 100.0% __libc_start_main /build/eglibc-3GlaMS/eglibc-2.19/csu/libc-start.c:287</span><br><span class="line">                   0   0.0% 100.0%       71 100.0% _start ??:?</span><br><span class="line">                   0   0.0% 100.0%        1   1.4% func1 /root/test.c:6</span><br><span class="line">                   0   0.0% 100.0%       11  15.5% func2 /root/test.c:12</span><br><span class="line">                   0   0.0% 100.0%       23  32.4% func3 /root/test.c:19 (discriminator 2)</span><br><span class="line">                   0   0.0% 100.0%       48  67.6% func3 /root/test.c:20 (discriminator 2)</span><br><span class="line">                   0   0.0% 100.0%       71 100.0% main /root/test.c:25</span><br><span class="line">            (--text, --pdf, --web, --dot, --gif, --gv etc )</span><br><span class="line">            ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br><span class="line"></span><br><span class="line">    Below seems not working for nginx don&#x27;t know why</span><br><span class="line"></span><br><span class="line">        TCMALLOC(thread cache malloc), you don&#x27;t need to memory management for your own</span><br><span class="line">        tcmalloc does it for you, so that you don&#x27;t need to care memory managment!!!!</span><br><span class="line"></span><br><span class="line">            tcmalloc actually implements a cache or pool, so that you can get memory from cache or pool</span><br><span class="line">            fast, but as the presure grows, tcmalloc takes more memory from system, while when presure decrease</span><br><span class="line">            tcmalloc should return the memory back to system TCMALLOC_RELEASE_RATE</span><br><span class="line">            Usage</span><br><span class="line">            +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br><span class="line">                #gcc -o test test.c -ltcmalloc_minimal</span><br><span class="line">                (in your program, use malloc, free as you did before)</span><br><span class="line">            +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br><span class="line"></span><br><span class="line">        HEAP CHECKER(check memory leak, not working well, don&#x27;t know why)</span><br><span class="line">            #gcc -o test test.c -ltcmalloc</span><br><span class="line">            #HEAPCHECK=normal  ./test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        HEAP Profile(check where/who alloc memory)</span><br><span class="line"></span><br><span class="line">            #gcc -o test test.c -ltcmalloc</span><br><span class="line"></span><br><span class="line">            dump heap profile when allocate 1M memory (only through malloc method)</span><br><span class="line">            #HEAPPROFILE=heap.prof HEAP_PROFILE_ALLOCATION_INTERVAL=1024*1024 ./test</span><br><span class="line"></span><br><span class="line">            also dump sbrk, mmap method as well</span><br><span class="line">            #HEAPPROFILE=heap.prof  HEAP_PROFILE_MMAP=true HEAP_PROFILE_ALLOCATION_INTERVAL=1024*1024 ./test</span><br><span class="line"></span><br><span class="line">            root@ubuntu:~#google-pprof --gv test test.0004.heap</span><br><span class="line">            root@centos:~#pprof --gv test test.0004.heap</span><br></pre></td></tr></table></figure>

<h1 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html">official load average</a></li>
<li><a target="_blank" rel="noopener" href="https://scoutapm.com/blog/understanding-load-averages">load average</a></li>
<li><a target="_blank" rel="noopener" href="https://www.quora.com/What-is-the-difference-between-load-and-CPU-usage-in-Unix-Linux">cpu load vs cpu usage</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/gperftools/gperftools">gperftools</a></li>
</ul>

    </div>

    
    
    
      


    <footer class="post-footer">
          <div class="reward-container">
  <div></div>
  <button>
    Donate
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.jpeg" alt="Jason WeChat Pay">
        <span>WeChat Pay</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/performance/" rel="tag"># performance</a>
              <a href="/tags/perf/" rel="tag"># perf</a>
              <a href="/tags/gperftools/" rel="tag"># gperftools</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2019/09/25/hexo-post/" rel="prev" title="hexo usage">
                  <i class="fa fa-chevron-left"></i> hexo usage
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2019/09/27/debugging-application/" rel="next" title="debugging application">
                  debugging application <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2018 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cyun All rights reserved</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.0/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>



  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>

  




<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"jason-bj/blog","issue_term":"pathname","theme":"github-light"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
